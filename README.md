# “One Model Fits All Nodes”: Neuron Activation  Pattern Analysis-Based Attack Traffic Detection  Framework for P2P Networks

## 本文解决的问题
在已知正常样本功能范围里面，解决模型在不同网络节点之间移植后，模型对**异常流量误判率较高**的问题
但**未涉及模型对未知样本、新型攻击流量的分类与识别**

## 新颖点
1. 提出看模型内部神经元的特点
2. 文章末尾提到了该模型对对抗攻击也有作用

## 模型结构
<img src="Screenshot 2025-11-07 164730.png">

## 各种攻击在没有tNeuron和有的情况下
<img src="Screenshot 2025-11-07 172724.png">

## 各种减小FP的模型在部署tNeuron优化对比
<img src="Screenshot 2025-11-07 172649.png">

## fig2里面的token construction是干什么的？
“Token Construction”（标记构造）是 tNeuron 框架训练阶段的第一个步骤，其主要目的是**构建用于训练 Transformer 影子模型（shadow model）的数据集 ${X_T, y_T}$** [1-3]。

tNeuron 设计 Token Construction 步骤是为了提取流量特征并生成可供影子模型学习的标签，从而提供用于后续神经元激活模式分析的丰富信息 [1, 4, 5]。

Token Construction 的具体工作内容和流程如下：

1.  **收集和组织数据包（Collect and Organize Packets）：**
    tNeuron 首先从用于训练（原始）检测模型的训练数据集中收集数据包 [1, 2]。然后，它根据数据包头中的五元组（five-tuples）将这些数据包组织成流（flows）[1, 2, 6]。
2.  **特征提取与标记化（Tokenization）：**
    tNeuron 随后对流中的每个数据包进行标记化（tokenization），方法是提取**每数据包的特征** [1]。具体提取的特征包括前 $L_{Max}$ 个数据包的**到达间隔（以微秒计）、IANA 协议号以及数据包长度（以字节计）** [2]。对于数据包数量少于 $L_{Max}$ 的流，tNeuron 会在剩余位置放置零向量进行表示 [2]。这个标记化的数据集被称为 $X_T$ [2, 3]。
3.  **掩盖与目标选择（Masking and Target Selection）：**
    tNeuron 会掩盖（mask）表示服务类型的端口号，因为这些字段是**将由影子模型预测的目标** [1]。
4.  **标签构建（Label Construction）：**
    为了构建标签 $y_T$，tNeuron 使用 **K-Means 算法**对源端口号和目标端口号（$y_p$），分别针对入站和出站流量进行聚类 [1, 3, 7]。
5.  **目标标签分配（Target Label Assignment）：**
    tNeuron 根据与端口号关联的**聚类中心**来为每个流构造标签 [1, 7]。这个步骤的目的是训练影子模型基于流量模式来预测这些端口号所属的聚类 [7]。

**为何选择端口号进行预测：**
tNeuron 训练影子模型来预测基于端口号的标签，是因为端口号可以为预测提供多样化的标签，并且这些标签可以直接获得，**无需大量人工工作** [7]。影子模型的准确性并不是重点，tNeuron 关注的是其神经元激活模式，用以分析流量知识 [8, 9]。

通过 Token Construction 步骤创建的 $X_T$ 和 $y_T$ 数据集将被用于后续的“Transformer Shadow Model Training”（Transformer 影子模型训练）阶段 [3, 10]。影子模型通过学习这些标记序列，提取流量模式的知识，并提供丰富的神经元激活模式，从而支撑 tNeuron 准确且鲁棒地检测误报（FPs）[4, 10, 11]。

形象地说，如果 tNeuron 的影子模型是一座旨在理解交通规则的 AI 大脑，那么“Token Construction”就像是**把原始的交通视频（数据包）剪辑成标准化的、带有明确标记（端口号类别）的短片（流特征 $X_T$ 和标签 $y_T$）**。这些标准化、易于学习的短片，帮助 AI 大脑理解正常的交通模式，即使它后来遇到未在训练中见过的交通场景（未见过的良性流量），也能通过比较神经元的反应（激活模式）来判断报警是否属于误报。
## 用通俗易懂的例子解释一下token construction？
假设您是一位交通专家，想要训练一个特殊的 AI（即 Transformer 影子模型）来理解“正常”的交通模式，以便它以后能识别出那些虽然不违规，但看起来“不正常”的交通行为（即 tNeuron 旨在识别的误报，FPs）。

**Token Construction 的工作流程就像是制作这套训练用的“知识卡片”：**

#### 1. 收集和整理素材（数据包和流）
*   **原始素材：** 城市中所有摄像头记录的原始交通数据（网络流量数据包）[1]。
*   **整理成“会话”：** 专家不会分析每一个单独的车辆，而是根据车辆的目的地和通信方式，将它们组织成一个个完整的“行程”或“会话”，比如从“A停车场到B购物中心的货运”或“C家到D公司的通勤”（即根据五元组将数据包组织成**流/Flows**）[1, 2]。

#### 2. 标准化特征提取（ $X_T$ 的构建）
这是“标记化”（Tokenization）的核心步骤。专家需要为每张知识卡片定义一个统一的格式，以便 AI 学习：

*   **只看关键步骤（ $L_{Max}$ ）：** 专家决定只关注行程中**前 $L_{Max}$ 个关键时刻**（即流中的前 $L_{Max}$ 个数据包），因为后面的步骤可能重复或不重要 [2]。
*   **记录三种关键信息（Per-Packet Features）：**
    1.  **间隔时间：** 距离上一个动作过了多久（**到达间隔**，用微秒计）。
    2.  **基本协议：** 使用了哪种交通工具的基础类型（**IANA 协议号**）。
    3.  **载货大小：** 车辆携带的载荷大小（**数据包长度**，用字节计）[2]。
*   **统一长度：** 如果一个会话不够 $L_{Max}$ 步，专家会在卡片后面填上空白（零向量），确保所有卡片长度一致，便于 AI 处理 [2]。

**成果：** 每一张卡片（ $X_T$ ）现在都是一个标准化的序列，描述了“一个交通会话在时间上的演变模式”。

#### 3. 构造预测目标（ $y_T$ 的构建）
AI 需要预测的目标不是交通会话的最终目的地，而是它**所属的活动类型**：

*   **识别“活动”特征：** 专家查看每个会话的关键识别信息——比如“起点”和“终点的门牌号”（即**源端口号和目标端口号**）[1]。
*   **聚类分类（K-Means）：** 城市里有数千个门牌号（端口号），无法让 AI 预测具体的门牌号。所以，专家使用 **K-Means 算法**，将所有相似的门牌号聚类成少数几个大的“活动区域”类别（Cluster Centers $C$ ） [1, 3]。例如：
    *   A区：零售活动（端口号聚类）。
    *   B区：文件传输活动（端口号聚类）。
*   **生成标签：** 每个会话的标签 $y_T$ 就是它被归属的那个**“活动区域”** [3]。
*   **隐藏答案（Masking）：** 在训练 AI 时，会把卡片上明显的“门牌号”信息遮盖起来（**Masked fields**），强迫 AI 只能通过学习**行为模式**（$X_T$ 中的时间、大小、协议）来猜测它属于哪个活动区域 [1]。

---

### 总结
**“标记构造”**就像是数据预处理和标签生成工厂 [1, 2]：它将复杂的原始网络数据包转化为**结构化序列（ $X_T$ ）**，并生成了**易于学习的、基于端口号聚类的类别标签（ $y_T$ ）** [3]。

这个过程的关键在于，它不要求人工标注每一段流量是“正常”还是“攻击”，而是利用端口号等现有信息自动生成训练标签，从而高效地训练出能够捕捉流量“知识”（神经元激活模式）的影子模型 [3]。

## 训练影子模型的时候是不是把正常样本和攻击样本一起训练？
tNeuron 的影子模型是使用包含**良性流量和攻击流量**的原始训练数据集构建的。

以下是详细的解释和来源支持：

### 1. 影子模型的训练数据来源

tNeuron 的训练阶段的第一步是“标记构造”（Token Construction），目的是为训练 Transformer 影子模型构建数据集 $\{X_T, y_T\}$ [1, 2]。

*   tNeuron 构造数据集 $\{X_T, y_T\}$ 的基础是原始数据集 $\{X_1, y_1, y_p\}$ [2]。
*   这个原始数据集 $\{X_1, y_1, y_p\}$ 是用于训练**攻击流量检测模型**（$M_D$）的 [1, 3]。
*   资料明确指出，原始数据集中的二元标签向量 $y_1$ **表示良性流和攻击流**（benign and attack flows）[4]。

因此，用于构造影子模型训练数据的 $X_1$ 包含了用于训练原始检测模型的所有流量，即**同时包含正常样本和攻击样本** [2, 4]。

### 2. 影子模型如何使用这些样本

虽然影子模型使用了良性样本和攻击样本，但它的训练目标（标签 $y_T$）与原始检测模型（$M_D$）的攻击/良性标签（$y_1$）**不同** [5, 6]。

*   **数据样本 ($X_T$)：** tNeuron 将 $X_1$ 中的每个流标记化，提取其特征（如到达间隔、协议号、数据包长度），形成序列数据 $X_T$ [4]。
*   **训练目标 ($y_T$)：** 影子模型是一个分类器，它被训练来预测基于**端口号的聚类标签** [6]。tNeuron 使用 **K-Means 算法**对源端口号和目标端口号进行聚类，并将流归类到聚类中心 $C_j$ 作为其标签 $y_T$ [5]。

**总结：**
tNeuron 影子模型训练的输入数据（流量模式 $X_T$）来自**包含良性流量和攻击流量**的原始数据集 $X_1$ [2, 4]，但其学习的目标是**预测端口号聚类**，而不是预测流量是良性还是攻击 [5, 6]。它通过学习这些复杂的序列模式，来提取流量知识，从而提供丰富的神经元激活模式供后续的误报检测使用 [6-8]。

